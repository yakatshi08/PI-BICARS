"""
Script d'installation des tests pour le Module Analytics ML
ExÃ©cution : python setup_tests.py
"""

import os
import sys

def create_test_files():
    """CrÃ©e tous les fichiers de test nÃ©cessaires"""
    
    # CrÃ©er le dossier tests
    if not os.path.exists('tests'):
        os.makedirs('tests')
        print("âœ… Dossier 'tests' crÃ©Ã©")
    
    # Contenu du test rapide
    quick_test_content = '''#!/usr/bin/env python3
"""
Test rapide du Module Analytics ML
ExÃ©cution : python quick_test_analytics.py
"""

import requests
import json
import numpy as np
from datetime import datetime, timedelta

# Configuration
API_URL = "http://localhost:8000/api/v1"  # Ajustez selon votre config
HEADERS = {"Content-Type": "application/json"}

def generate_test_data():
    """GÃ©nÃ¨re des donnÃ©es de test simples"""
    dates = [(datetime.now() - timedelta(days=x)).isoformat() for x in range(100, 0, -1)]
    values = [100 + x + np.random.normal(0, 5) for x in range(100)]
    
    return [{"date": d, "value": v} for d, v in zip(dates, values)]

def test_endpoint(name, endpoint, payload):
    """Test un endpoint et affiche le rÃ©sultat"""
    print(f"\\nğŸ” Test: {name}")
    print(f"   Endpoint: {endpoint}")
    
    try:
        response = requests.post(f"{API_URL}{endpoint}", json=payload, headers=HEADERS)
        
        if response.status_code == 200:
            print(f"   âœ… SuccÃ¨s (200 OK)")
            result = response.json()
            
            # Afficher quelques infos clÃ©s
            if "predictions" in result:
                print(f"   ğŸ“Š PrÃ©dictions gÃ©nÃ©rÃ©es: {len(result['predictions'])}")
            if "selected_model" in result:
                print(f"   ğŸ¤– ModÃ¨le sÃ©lectionnÃ©: {result['selected_model']}")
            if "anomalies" in result:
                print(f"   âš ï¸  Anomalies dÃ©tectÃ©es: {len(result['anomalies'])}")
            
            return True
        else:
            print(f"   âŒ Ã‰chec ({response.status_code})")
            print(f"   Erreur: {response.text[:200]}")
            return False
            
    except Exception as e:
        print(f"   âŒ Exception: {str(e)}")
        return False

def main():
    """Tests rapides principaux"""
    print("="*60)
    print("ğŸš€ TEST RAPIDE - MODULE ANALYTICS ML")
    print("="*60)
    
    # GÃ©nÃ©rer les donnÃ©es de test
    test_data = generate_test_data()
    print(f"\\nğŸ“Š DonnÃ©es de test gÃ©nÃ©rÃ©es: {len(test_data)} points")
    
    # Liste des tests Ã  effectuer
    tests = [
        {
            "name": "PrÃ©diction automatique",
            "endpoint": "/analytics/predict/auto",
            "payload": {
                "data": test_data,
                "target_column": "value",
                "forecast_horizon": 10
            }
        },
        {
            "name": "DÃ©tection d'anomalies",
            "endpoint": "/analytics/anomalies/detect",
            "payload": {
                "data": test_data,
                "target_column": "value",
                "method": "isolation_forest"
            }
        },
        {
            "name": "Pipeline AutoML",
            "endpoint": "/analytics/automl/run",
            "payload": {
                "data": test_data,
                "target_column": "value",
                "models_to_test": ["xgboost", "prophet"],
                "validation_strategy": "time_series_split"
            }
        },
        {
            "name": "Analyse de scÃ©narios",
            "endpoint": "/analytics/scenarios/analyze",
            "payload": {
                "base_data": [d["value"] for d in test_data],
                "scenarios": [
                    {"name": "Optimiste", "growth_rate": 0.1},
                    {"name": "Pessimiste", "growth_rate": -0.1}
                ],
                "horizon": 30
            }
        }
    ]
    
    # ExÃ©cuter les tests
    results = []
    for test in tests:
        success = test_endpoint(test["name"], test["endpoint"], test["payload"])
        results.append((test["name"], success))
    
    # RÃ©sumÃ©
    print("\\n" + "="*60)
    print("ğŸ“Š RÃ‰SUMÃ‰ DES TESTS")
    print("="*60)
    
    passed = sum(1 for _, success in results if success)
    total = len(results)
    
    for name, success in results:
        status = "âœ… PASS" if success else "âŒ FAIL"
        print(f"{status} - {name}")
    
    print(f"\\nğŸ“ˆ Score: {passed}/{total} ({passed/total*100:.0f}%)")
    
    if passed == total:
        print("\\nğŸ‰ Tous les tests sont passÃ©s avec succÃ¨s!")
        print("âœ¨ Le Module Analytics ML est opÃ©rationnel!")
    else:
        print("\\nâš ï¸  Certains tests ont Ã©chouÃ©.")
        print("ğŸ“‹ VÃ©rifiez que l'API est bien dÃ©marrÃ©e et accessible.")
    
    # Test de santÃ© de l'API
    print("\\nğŸ¥ Test de santÃ© de l'API...")
    try:
        health_response = requests.get(f"{API_URL}/health")
        if health_response.status_code == 200:
            print("âœ… L'API est accessible")
        else:
            print("âŒ L'API ne rÃ©pond pas correctement")
    except:
        print("âŒ Impossible de joindre l'API")
        print(f"   VÃ©rifiez que le serveur est dÃ©marrÃ© sur {API_URL}")

if __name__ == "__main__":
    main()
'''

    # Contenu du README
    readme_content = '''# Guide des Tests - Module Analytics ML

## ğŸ“‹ Installation rapide

```bash
# 1. Installer les dÃ©pendances
pip install pytest numpy pandas requests

# 2. Lancer le test rapide
python tests/quick_test_analytics.py

# 3. Lancer la suite complÃ¨te (optionnel)
python tests/test_analytics_ml.py
```

## ğŸš€ Configuration

Avant de lancer les tests, assurez-vous que :
1. Votre API est dÃ©marrÃ©e (par dÃ©faut sur http://localhost:8000)
2. Les endpoints sont accessibles
3. Les dÃ©pendances sont installÃ©es

## ğŸ“Š RÃ©sultats attendus

Si tout fonctionne :
- âœ… 4/4 tests passÃ©s pour le test rapide
- âœ… 14/14 tests passÃ©s pour la suite complÃ¨te
'''

    # Ã‰crire les fichiers
    with open('tests/quick_test_analytics.py', 'w', encoding='utf-8') as f:
        f.write(quick_test_content)
    print("âœ… Fichier 'tests/quick_test_analytics.py' crÃ©Ã©")
    
    with open('tests/README.md', 'w', encoding='utf-8') as f:
        f.write(readme_content)
    print("âœ… Fichier 'tests/README.md' crÃ©Ã©")
    
    print("\nğŸ“‹ Note: Le fichier test_analytics_ml.py (suite complÃ¨te) est trop long")
    print("   Copiez-le manuellement depuis l'artifact si vous voulez tous les tests")

def install_dependencies():
    """Installe les dÃ©pendances nÃ©cessaires"""
    print("\nğŸ“¦ Installation des dÃ©pendances...")
    
    try:
        import subprocess
        subprocess.check_call([sys.executable, "-m", "pip", "install", 
                             "pytest", "numpy", "pandas", "requests"])
        print("âœ… DÃ©pendances installÃ©es avec succÃ¨s")
        return True
    except Exception as e:
        print(f"âŒ Erreur lors de l'installation : {e}")
        print("   Installez manuellement : pip install pytest numpy pandas requests")
        return False

def main():
    print("="*60)
    print("ğŸ› ï¸  SETUP DES TESTS - MODULE ANALYTICS ML")
    print("="*60)
    
    # CrÃ©er les fichiers
    create_test_files()
    
    # Proposer d'installer les dÃ©pendances
    print("\nâ“ Voulez-vous installer les dÃ©pendances ? (o/n)")
    response = input().lower()
    
    if response == 'o':
        install_dependencies()
    
    # Instructions finales
    print("\n" + "="*60)
    print("âœ… SETUP TERMINÃ‰!")
    print("="*60)
    print("\nğŸš€ Pour lancer les tests :")
    print("   1. Assurez-vous que votre API est dÃ©marrÃ©e")
    print("   2. ExÃ©cutez : python tests\\quick_test_analytics.py")
    print("\nğŸ’¡ Conseil : Commencez par le test rapide pour valider")
    print("   que votre API fonctionne correctement.")

if __name__ == "__main__":
    main()